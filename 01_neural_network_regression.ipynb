{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_neural_network_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51x_WlMr_3z5"
      },
      "source": [
        "Name: Aryan Kapoor \n",
        "\n",
        "Topic: Tensorflow - Linear regression Full including the normalization\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRtAkr5sNUoN",
        "outputId": "29e93dc6-e97e-4021-a3bd-a786ddf434dd"
      },
      "source": [
        " from google.colab import drive\n",
        "drive.mount('/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1gLh7wMNkjb"
      },
      "source": [
        "### Introduction to Regression with Tensorflow\n",
        "\n",
        "Predicting a numerical variable based on some other combination of variable, even shorter.. predicting a number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73F7lvfiOKtI",
        "outputId": "ce41f714-254b-437c-c5e3-fb7b1bbca1d1"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3KoO9xoOTie"
      },
      "source": [
        "## Crating data to view and fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "ldYlOuIUOnbj",
        "outputId": "12de8031-a76b-47a6-d957-188d4e21d34b"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Create features\n",
        "\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "#Creating labels\n",
        "\n",
        "y = np.array([3., 6., 9., 12., 15., 18., 21., 24.])\n",
        "\n",
        "plt.scatter(X,y)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f85716618d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOP0lEQVR4nO3df2jc933H8ddrigZHGlCCVWNpMR4lHIRBrU6EQctIadfL8o+Vf8LyR/FYwPmjgY6Vg6j/NDAGYdcf/2wUHBriQZtRqKKEUXrNTJkpjDG5MpXT7EgpNsvJsR26oxl8YYr63h/6npFcS/dDd/refe75AKG7z33le/NFeeb8/X7P54gQACAdv1f0AACAwSLsAJAYwg4AiSHsAJAYwg4AiSHsAJCYjmG3/bDtn9j+he23bX85X3/RdtP2lfzryeGPCwDoxJ2uY7d9QtKJiPiZ7QckXZa0JOlpSf8bEV8f/pgAgG7d12mDiLgh6UZ++0Pb70iaH/ZgAID+dHzFvmdj+5SkS5L+SNLfSPpLSb+RtCbpKxHxPwf9/LFjx+LUqVP9TQoAE+ry5csfRMRst9t3HXbbH5P0b5L+LiJWbB+X9IGkkPS32jlc81f3+Llzks5J0smTJ//4+vXr3c4GAJBk+3JELHa7fVdXxdielvQDSd+NiBVJioibEbEdEb+V9LKkx+71sxFxPiIWI2Jxdrbr/+EAAPrUzVUxlvQdSe9ExDd3rZ/YtdlTkq4OfjwAQK86njyV9GlJX5S0YftKvvZVSc/YPq2dQzHXJD03lAkBAD3p5qqYn0ryPR764eDHAQAcFu88BYDEdHMoBgDQp9X1pmr1hjZbmeZmSqpWylpaGO5bgQg7AAzJ6npTyysbyra2JUnNVqbllQ1JGmrcORQDAENSqzfuRL0t29pWrd4Y6vMSdgAYks1W1tP6oBB2ABiSuZlST+uDQtgBYEiqlbJK01N71krTU6pWykN9Xk6eAsCQtE+QclUMACRkaWF+6CG/G4diACAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEsOHWQMYK6vrTdXqDW22Ms3NlFStlI/8w6JHHWEHMDZW15taXtlQtrUtSWq2Mi2vbEgScd+FQzEAxkat3rgT9bZsa1u1eqOgiUYTYQcwNjZbWU/rk4qwAxgbczOlntYnFWEHMDaqlbJK01N71krTU6pWygVNNJo4eQpgbLRPkHJVzMEIO4CxsrQwT8g74FAMACSmY9htP2z7J7Z/Yftt21/O1x+y/Zbtd/PvDw5/XABAJ928Yv9I0lci4lFJfyLpS7YflfSCpIsR8Yiki/l9AEDBOoY9Im5ExM/y2x9KekfSvKQzki7km12QtDSsIQEA3evpGLvtU5IWJP2HpOMRcSN/6H1Jxwc6GQCgL12H3fbHJP1A0l9HxG92PxYRISn2+blzttdsr92+fftQwwIAOusq7LantRP170bESr580/aJ/PETkm7d62cj4nxELEbE4uzs7CBmBgAcoJurYizpO5LeiYhv7nroTUln89tnJb0x+PEAAL3q5g1Kn5b0RUkbtq/ka1+V9JKk79t+VtJ1SU8PZ0QAQC86hj0ifirJ+zz8ucGOAwA4LN55CgCJIewAkBjCDgCJIewAkBjCDgCJIewAkBjCDgCJIewAkBjCDgCJIewAkBjCDgCJ6eYfAQOQuNX1pmr1hjZbmeZmSqpWylpamC96LPSJsAMTbnW9qeWVDWVb25KkZivT8sqGJBH3McWhGGDC1eqNO1Fvy7a2Vas3CpoIh0XYgQm32cp6WsfoI+zAhJubKfW0jtFH2IEJV62UVZqe2rNWmp5StVIuaCIcFidPgQnXPkHKVTHpIOwAtLQwT8gTwqEYAEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxBB2AEhMx7DbfsX2LdtXd629aLtp+0r+9eRwxwQAdKubD7N+VdI/SPqnu9a/FRFfH/hEQAJW15uq1RvabGWamympWinzYdE4Mh3DHhGXbJ8a/ihAGlbXm1pe2VC2tS1JarYyLa9sSBJxx5E4zDH2523/PD9U8+DAJgLGXK3euBP1tmxrW7V6o6CJMGn6Dfu3JX1C0mlJNyR9Y78NbZ+zvWZ77fbt230+HTA+NltZT+vAoPUV9oi4GRHbEfFbSS9LeuyAbc9HxGJELM7OzvY7JzA25mZKPa0Dg9ZX2G2f2HX3KUlX99sWmDTVSlml6ak9a6XpKVUr5YImwqTpePLU9muSHpd0zPZ7kr4m6XHbpyWFpGuSnhvijMBYaZ8g5aoYFMURcWRPtri4GGtra0f2fACQAtuXI2Kx2+155ykAJIawA0BiCDsAJIawA0BiCDsAJIawA0BiCDsAJIawA0BiCDsAJIawA0BiCDsAJIawA0BiCDsAJIawA0BiCDsAJIawA0BiCDsAJIawA0BiCDsAJIawA0Bi7it6AKBbq+tN1eoNbbYyzc2UVK2UtbQwX/RYwMgh7BgLq+tNLa9sKNvaliQ1W5mWVzYkibgDd+FQDMZCrd64E/W2bGtbtXqjoImA0UXYMRY2W1lP68AkI+wYC3MzpZ7WgUlG2DEWqpWyStNTe9ZK01OqVsoFTQSMLk6eYiy0T5ByVQzQGWHH2FhamCfkQBc4FAMAiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJCYjmG3/YrtW7av7lp7yPZbtt/Nvz843DEBAN3q5hX7q5KeuGvtBUkXI+IRSRfz+wCAEdAx7BFxSdKv71o+I+lCfvuCpKUBzwUA6FO/x9iPR8SN/Pb7ko4PaB4AwCEd+uRpRISk2O9x2+dsr9leu3379mGfDgDQQb9hv2n7hCTl32/tt2FEnI+IxYhYnJ2d7fPpAADd6jfsb0o6m98+K+mNwYwDADisbi53fE3Sv0sq237P9rOSXpL0Z7bflfT5/D4AYAR0/Gi8iHhmn4c+N+BZAAADwDtPASAxfJj1BFtdb6pWb2izlWlupqRqpcyHRQMJIOwTanW9qeWVDWVb25KkZivT8sqGJBF3YMxxKGZC1eqNO1Fvy7a2Vas3CpoIwKAQ9gm12cp6WgcwPgj7hJqbKfW0DmB8EPYJVa2UVZqe2rNWmp5StVIuaCIAg8LJ0wnVPkHKVTFAegj7BFtamCfkQII4FAMAiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4Aibmv6AFSs7reVK3e0GYr09xMSdVKWUsL80WPBWCCEPYBWl1vanllQ9nWtiSp2cq0vLIhScQdwJHhUMwA1eqNO1Fvy7a2Vas3CpoIwCQi7AO02cp6WgeAYSDsAzQ3U+ppHQCGgbAPULVSVml6as9aaXpK1Uq5oIkATCJOng5Q+wQpV8UAKBJhH7ClhXlCDqBQhwq77WuSPpS0LemjiFgcxFAAgP4N4hX7ZyPigwH8OQCAAeDkKQAk5rBhD0k/tn3Z9rlBDAQAOJzDHor5TEQ0bX9c0lu2/ysiLu3eIA/+OUk6efLkIZ8OANDJoV6xR0Qz/35L0uuSHrvHNucjYjEiFmdnZw/zdACALvQddtv3236gfVvSFyRdHdRgAID+HOZQzHFJr9tu/znfi4gfDWQqAEDf+g57RPxK0icHOAsAYAC43BEAEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEjPyH2a9ut5Urd7QZivT3ExJ1UqZD4sGgAOMdNhX15taXtlQtrUtSWq2Mi2vbEgScQeAfYz0oZhavXEn6m3Z1rZq9UZBEwHA6BvpsG+2sp7WAQAjHva5mVJP6wCAEQ97tVJWaXpqz1ppekrVSrmgiQBg9I30ydP2CVKuigGA7o102KWduBNyAOjeSB+KAQD0jrADQGIIOwAkhrADQGIIOwAkxhFxdE9m35Z0/cie8PCOSfqg6CFGHPvoYOyfzthHBzsm6f6ImO32B4407OPG9lpELBY9xyhjHx2M/dMZ++hg/ewfDsUAQGIIOwAkhrAf7HzRA4wB9tHB2D+dsY8O1vP+4Rg7ACSGV+wAkBjC3oHtF203bV/Jv54seqZRYPsJ2w3bv7T9QtHzjCLb12xv5L83a0XPUzTbr9i+ZfvqrrWHbL9l+938+4NFzli0ffZRzw0i7N35VkSczr9+WPQwRbM9JekfJf25pEclPWP70WKnGlmfzX9vuJxPelXSE3etvSDpYkQ8Iulifn+Svarf3UdSjw0i7OjHY5J+GRG/ioj/k/TPks4UPBNGXERckvTru5bPSLqQ374gaelIhxox++yjnhH27jxv++f5X5Mm+q+KuXlJ/73r/nv5GvYKST+2fdn2uaKHGVHHI+JGfvt9SceLHGaE9dQgwi7J9r/avnqPrzOSvi3pE5JOS7oh6RuFDotx8pmI+JR2Dll9yfafFj3QKIudS/S4TO939dygkf8EpaMQEZ/vZjvbL0v6lyGPMw6akh7edf8P8jXsEhHN/Pst269r5xDWpWKnGjk3bZ+IiBu2T0i6VfRAoyYibrZvd9sgXrF3kP+ytT0l6ep+206Q/5T0iO0/tP37kv5C0psFzzRSbN9v+4H2bUlfEL879/KmpLP57bOS3ihwlpHUT4N4xd7Z39s+rZ2/Il6T9Fyx4xQvIj6y/bykuqQpSa9ExNsFjzVqjkt63ba089/Z9yLiR8WOVCzbr0l6XNIx2+9J+pqklyR93/az2vmXX58ubsLi7bOPHu+1QbzzFAASw6EYAEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxPw/YhrWmPXy7VoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mwIiOXkPVw4"
      },
      "source": [
        "### Input and Output Shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDb3nBZpPerz"
      },
      "source": [
        "# Create a demo tensor for our housing price prediction problem \n",
        "\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYC8BS-jTw5-"
      },
      "source": [
        "# Turn to tensorns \n",
        "\n",
        "X = tf.constant(X)\n",
        "y = tf.constant(y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE_wt1tRT5_y"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xjLvsxhUHzO",
        "outputId": "e66e6ad5-749a-4fdb-dea0-dd583392757e"
      },
      "source": [
        "input_shape, output_shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDBZIznsUK5z"
      },
      "source": [
        "### Steps in modelling with Tensor flow\n",
        "\n",
        "1. **Creating a model** - define the input output layers, as well as the hidden layers of deep learning model.\n",
        "2. **Compiling the model** - defina the loss function(in other words the function which tells is how worng the model is) and optimizer(tells the model how to improve the patterns its learing) and evalution metrics(what can we use to interpret the performance of our model).\n",
        "3. **Fitting the model** - letting the model try to find patterns between X & y(Features and labels)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMF3i3-8Vb8z",
        "outputId": "85c343fa-2545-4efa-b188-1c1ab1bbe23e"
      },
      "source": [
        "#Set seed \n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#Create a model using sequential API \n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2 compile the model \n",
        "\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "#fit\n",
        "\n",
        "model.fit(X, y, epochs=5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 3s 3s/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.9748 - mae: 10.9748\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8571e7ead0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgcZyAeNX2yg",
        "outputId": "bd0df94f-b0a4-4959-f0ab-e4337aef48be"
      },
      "source": [
        "model.predict([17.])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0gqCwcVYvE5"
      },
      "source": [
        "### Imporving the model\n",
        "\n",
        "We can imporve our model by altering the steps we took in imporving our model \n",
        "\n",
        "1. **Creating Model** - We might add more layers, increase the number of hidden layes, change the activation function \n",
        "\n",
        "2. **Compiling Model** - Here we might change the optimizer \n",
        "\n",
        "3. **Fitting Model** - here we might increase number of epochs or we might increase the dataset size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBbOB7K0yTlB",
        "outputId": "5745bbfd-7690-46d8-b77d-ca70bf06ba05"
      },
      "source": [
        "# Lets rebuild our model \n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# compiling\n",
        "\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "#Fitting the model\n",
        "\n",
        "model.fit(X, y, epochs=100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 11.2219 - mae: 11.2219\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.0894 - mae: 11.0894\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.9569 - mae: 10.9569\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.8244 - mae: 10.8244\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.6919 - mae: 10.6919\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.5594 - mae: 10.5594\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.4269 - mae: 10.4269\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.2944 - mae: 10.2944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.1619 - mae: 10.1619\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.8969 - mae: 9.8969\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.7644 - mae: 9.7644\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.6319 - mae: 9.6319\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.4994 - mae: 9.4994\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.2344 - mae: 9.2344\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.1019 - mae: 9.1019\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.9694 - mae: 8.9694\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.8369 - mae: 8.8369\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7044 - mae: 8.7044\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5719 - mae: 8.5719\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.4394 - mae: 8.4394\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.3069 - mae: 8.3069\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.1744 - mae: 8.1744\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.0419 - mae: 8.0419\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.9094 - mae: 7.9094\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.7769 - mae: 7.7769\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.6444 - mae: 7.6444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.5119 - mae: 7.5119\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.3794 - mae: 7.3794\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2413 - mae: 7.2413\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9262 - mae: 6.9262\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.8869 - mae: 6.8869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f852403f210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1J-WzJt5_ra",
        "outputId": "2807e2a6-3e8b-4b05-9842-56367552577c"
      },
      "source": [
        "model.predict([17.])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.739855]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkoXmnlN6Fdm",
        "outputId": "770ba078-5ac7-48f0-cf85-fd853fd8c3bf"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(100,activation=\"relu\"),\n",
        "                             tf.keras.layers.Dense(100,activation=\"relu\"),\n",
        "                             tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              metrics=\"mae\")\n",
        "\n",
        "model.fit(X,y,epochs=100)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 14.1593 - mae: 14.1593\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.3429 - mae: 11.3429\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.3572 - mae: 9.3572\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.5496 - mae: 7.5496\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4983 - mae: 5.4983\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.0591 - mae: 4.0591\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.8500 - mae: 4.8500\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.4655 - mae: 5.4655\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.5195 - mae: 5.5195\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.1762 - mae: 5.1762\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.5788 - mae: 4.5788\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9925 - mae: 3.9925\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.6979 - mae: 3.6979\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.9708 - mae: 3.9708\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2083 - mae: 4.2083\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9294 - mae: 3.9294\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5208 - mae: 3.5208\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3878 - mae: 3.3878\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.4360 - mae: 3.4360\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.5180 - mae: 3.5180\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.4169 - mae: 3.4169\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1497 - mae: 3.1497\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9422 - mae: 2.9422\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7772 - mae: 2.7772\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6383 - mae: 2.6383\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.5325 - mae: 2.5325\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2743 - mae: 2.2743\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0701 - mae: 2.0701\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9602 - mae: 1.9602\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6620 - mae: 1.6620\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.3829 - mae: 1.3829\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1895 - mae: 1.1895\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8293 - mae: 0.8293\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6545 - mae: 0.6545\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3525 - mae: 0.3525\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6983 - mae: 0.6983\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6721 - mae: 0.6721\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1198 - mae: 1.1198\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8163 - mae: 0.8163\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9054 - mae: 0.9054\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9688 - mae: 0.9688\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6424 - mae: 0.6424\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9588 - mae: 0.9588\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6450 - mae: 0.6450\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6846 - mae: 0.6846\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0807 - mae: 1.0807\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6466 - mae: 0.6466\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6345 - mae: 0.6345\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9012 - mae: 0.9012\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4620 - mae: 0.4620\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8497 - mae: 0.8497\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1140 - mae: 1.1140\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6863 - mae: 0.6863\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6319 - mae: 0.6319\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8925 - mae: 0.8925\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5621 - mae: 0.5621\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5421 - mae: 0.5421\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6743 - mae: 0.6743\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1771 - mae: 0.1771\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9795 - mae: 0.9795\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2567 - mae: 1.2567\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9706 - mae: 0.9706\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1926 - mae: 0.1926\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4988 - mae: 0.4988\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3403 - mae: 0.3403\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5129 - mae: 0.5129\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5465 - mae: 0.5465\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1598 - mae: 0.1598\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9993 - mae: 0.9993\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3082 - mae: 1.3082\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1228 - mae: 1.1228\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5134 - mae: 0.5134\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7162 - mae: 0.7162\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1385 - mae: 1.1385\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0421 - mae: 1.0421\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3950 - mae: 0.3950\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8061 - mae: 0.8061\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2649 - mae: 1.2649\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2426 - mae: 1.2426\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7621 - mae: 0.7621\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2039 - mae: 0.2039\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6340 - mae: 0.6340\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5071 - mae: 0.5071\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1259 - mae: 0.1259\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2056 - mae: 0.2056\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2307 - mae: 0.2307\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1494 - mae: 0.1494\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2947 - mae: 0.2947\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1716 - mae: 0.1716\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4895 - mae: 0.4895\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4797 - mae: 0.4797\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0938 - mae: 0.0938\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6066 - mae: 0.6066\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7110 - mae: 0.7110\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3410 - mae: 0.3410\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4653 - mae: 0.4653\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6757 - mae: 0.6757\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3369 - mae: 0.3369\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5076 - mae: 0.5076\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7579 - mae: 0.7579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8512542590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncMGeF997o27",
        "outputId": "df5d66b0-73ed-46e0-c64b-20d75ec00ac6"
      },
      "source": [
        "model.predict([17.])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[25.886602]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C8F-nSI78aC"
      },
      "source": [
        "## Evaluting model \n",
        "\n",
        "In practice the common work flow is to build a model fit it evaluate it tweat a model (To see that the model is optmised or not and if not than improve the model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7izIc7Ut-SUt"
      },
      "source": [
        "When it comes to evalution there are 3 words to focus on \n",
        "\n",
        "\"Visualse Visualse Visualse\" \n",
        "\n",
        "* Visualze the data - What data are we working with\n",
        "* The model itself - what our model look like\n",
        "* The training of the model - how does our model preforms when it trains\n",
        "* The predictions of the model - How does our model predit the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRfHaMzi_AVv",
        "outputId": "2d72d1e7-edec-4ddf-82be-1e71645f9721"
      },
      "source": [
        "# Make a bigger dataset\n",
        "\n",
        "X = tf.range(-100, 100, 4)\n",
        "X"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K__n0tI4_ULy",
        "outputId": "0f6719a0-465e-4401-bcb0-8879b130fa89"
      },
      "source": [
        "y = X + 10\n",
        "y"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "BSgQBfsj_Ywj",
        "outputId": "7db49980-5fb4-4638-a9b0-620caf283e5b"
      },
      "source": [
        "# Visulize the date\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X,y)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f85124176d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIgsBSMv_qIV"
      },
      "source": [
        "### The 3 sets... \n",
        "\n",
        "* Teining Set - the model learns from this set of data\n",
        "* Validation set - this is what the model with get tuned on data 10 - 15% of the data available\n",
        "* Test set - the model gets evaluted on the test set this is typcally 10-15% for the data available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-rLkYK_AjWL",
        "outputId": "1f880147-a263-4d33-a075-d2a903c25315"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-8B9KzLAzgv",
        "outputId": "edd0b394-cb89-43d5-95c7-fae42ed71ff6"
      },
      "source": [
        "# slpit the data into train and test set \n",
        "X_train = X[:40] \n",
        "X_test = X[40:] # LAst 10 samples\n",
        "\n",
        "y_train = y[:40]\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test) "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vnf8623Bjps"
      },
      "source": [
        "### Visualze the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "TeNs_oesBpXe",
        "outputId": "79402a1d-15ff-4cf5-e3fa-21e4af3f44c6"
      },
      "source": [
        "plt.scatter(X_train, y_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f85123c2fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNvj1p4YByh1",
        "outputId": "354b3ff3-715d-479f-a2cb-b7d8a7019401"
      },
      "source": [
        "# Let's build a neural network \n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 27.5487 - mae: 27.5487\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7192 - mae: 8.7192\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.9165 - mae: 10.9165\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1627 - mae: 11.1627\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.6115 - mae: 12.6115\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7758 - mae: 9.7758\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.6359 - mae: 8.6359\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.2237 - mae: 9.2237\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.9830 - mae: 19.9830\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9103 - mae: 9.9103\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7360 - mae: 8.7360\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.1700 - mae: 11.1700\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.2177 - mae: 10.2177\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3510 - mae: 9.3510\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.1028 - mae: 14.1028\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.9702 - mae: 8.9702\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.8682 - mae: 12.8682\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.7529 - mae: 10.7529\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.2981 - mae: 20.2981\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.5572 - mae: 16.5572\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.8305 - mae: 11.8305\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.8359 - mae: 8.8359\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4009 - mae: 10.4009\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.2307 - mae: 16.2307\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.1282 - mae: 12.1282\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.4574 - mae: 13.4574\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.5760 - mae: 10.5760\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.0203 - mae: 13.0203\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2802 - mae: 9.2802\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.2107 - mae: 17.2107\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24.4945 - mae: 24.4945\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6457 - mae: 7.6457\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.2562 - mae: 9.2562\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.0891 - mae: 14.0891\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.9085 - mae: 10.9085\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.6530 - mae: 13.6530\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2939 - mae: 9.2939\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.4248 - mae: 10.4248\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.1856 - mae: 9.1856\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7219 - mae: 9.7219\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.1841 - mae: 10.1841\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 10.8666 - mae: 10.8666\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.3873 - mae: 7.3873\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.8800 - mae: 7.8800\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.9278 - mae: 9.9278\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.9713 - mae: 8.9713\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.4343 - mae: 7.4343\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4139 - mae: 8.4139\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.3526 - mae: 10.3526\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.9244 - mae: 8.9244\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 11.0086 - mae: 11.0086\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.8157 - mae: 15.8157\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.0832 - mae: 15.0832\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.4437 - mae: 22.4437\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.6979 - mae: 16.6979\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.2421 - mae: 10.2421\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5354 - mae: 9.5354\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.2590 - mae: 9.2590\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.1435 - mae: 8.1435\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.4811 - mae: 9.4811\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.5094 - mae: 11.5094\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.0683 - mae: 12.0683\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3620 - mae: 7.3620\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.8784 - mae: 12.8784\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.8156 - mae: 10.8156\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.1504 - mae: 16.1504\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7944 - mae: 9.7944\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.4801 - mae: 8.4801\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.7049 - mae: 13.7049\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.1673 - mae: 7.1673\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.5865 - mae: 12.5865\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3490 - mae: 8.3490\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.9208 - mae: 6.9208\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.8217 - mae: 9.8217\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0453 - mae: 10.0453\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.0178 - mae: 10.0178\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.4224 - mae: 13.4224\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.8312 - mae: 10.8312\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.1943 - mae: 16.1943\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.0504 - mae: 12.0504\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.2696 - mae: 9.2696\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.1551 - mae: 13.1551\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.5633 - mae: 10.5633\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6684 - mae: 10.6684\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1796 - mae: 9.1796\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.9471 - mae: 8.9471\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.1226 - mae: 12.1226\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4538 - mae: 10.4538\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1459 - mae: 7.1459\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.8748 - mae: 12.8748\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1127 - mae: 7.1127\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4426 - mae: 7.4426\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.0516 - mae: 7.0516\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.7329 - mae: 12.7329\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7460 - mae: 9.7460\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.4563 - mae: 8.4563\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.4880 - mae: 12.4880\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.8845 - mae: 8.8845\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.3402 - mae: 8.3402\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.0960 - mae: 15.0960\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f851232c590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVg-rhA8DEUo"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                              tf.keras.layers.Dense(10, input_shape=[1], name=\"Input_layer\"),\n",
        "                              tf.keras.layers.Dense(1, input_shape=[1], name=\"output_layer\")\n",
        "])\n",
        "\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['mae'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYhiszNcE7B9",
        "outputId": "c7e75ac5-6664-40f3-ca08-a75e8e2bed7c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input_layer (Dense)          (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGJmdafBE-Ql"
      },
      "source": [
        "* Total Params - total number of params in the model\n",
        "* Trainable Params - these are the parameters the model can update as in trains\n",
        "* Non trainable params - these parameters aren't updated during the training(When you bring in the already trained model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpaY1tRiGRD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9954f2fe-53f4-4f49-ee7d-2798c796fe41"
      },
      "source": [
        "model.fit(X_train,y_train,epochs=100,verbose=0)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8512224050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvhDIA9gjwE1",
        "outputId": "ca1c2b95-a076-4e48-f400-539d78666414"
      },
      "source": [
        "model.summary()\n",
        " "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input_layer (Dense)          (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V8-58lFly7b"
      },
      "source": [
        "### Visualize our model predictions\n",
        "\n",
        "To visualize the predictions it's good idea to plot them against the ground truth lables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbHul2N_usld"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model as plot"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0JVBWkhu3MG",
        "outputId": "fe56db79-d170-4f8b-9562-24a98665beb0"
      },
      "source": [
        "# make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 70.55219 ],\n",
              "       [ 75.139915],\n",
              "       [ 79.72764 ],\n",
              "       [ 84.31536 ],\n",
              "       [ 88.90308 ],\n",
              "       [ 93.49081 ],\n",
              "       [ 98.07853 ],\n",
              "       [102.66626 ],\n",
              "       [107.253975],\n",
              "       [111.841705]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efP4A60OvWh5"
      },
      "source": [
        "# Let's create a plotting function\n",
        "\n",
        "def polt_predictions(training_data = X_train,\n",
        "                     training_labels = y_train,\n",
        "                     test_data = X_test,\n",
        "                     test_labels = y_test,\n",
        "                     predictions = y_pred):\n",
        "  \n",
        "  plt.figure(figsize=(10,7))\n",
        "  # training data in blue\n",
        "\n",
        "  plt.scatter(training_data, training_labels, c=\"b\", label=\"Training data\")\n",
        "\n",
        "  # testing data in green \n",
        "\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", label = \"Testing Data\")\n",
        "\n",
        "  # predictions in red \n",
        "\n",
        "  plt.scatter(test_data, y_pred, c=\"r\", label = \"Predications\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "8TDQQfTnxF3y",
        "outputId": "feb2f724-8635-4c53-f28b-753c43114dda"
      },
      "source": [
        "polt_predictions()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-60ED4BxbXJ"
      },
      "source": [
        "### Evaluating our model prediction with regression evaluation metrics\n",
        "\n",
        "Depending on the problem you are working on there can be different evaluation metrics to evaluate you model \n",
        "\n",
        "* MAE\n",
        "* MSE(Mean Square Error)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItrgG5quyrO4",
        "outputId": "e57ca84c-d156-4642-98ca-11ad12502db3"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 102ms/step - loss: 3.1969 - mae: 3.1969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.196946620941162, 3.196946620941162]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOzRxBR10dGk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "923a1eae-40ce-48ef-d6c5-0ada022d37eb"
      },
      "source": [
        "# calculate the mean absolute error\n",
        "\n",
        "mae = tf.metrics.mean_absolute_error(y_test,y_pred)\n",
        "mae"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([17.558247, 14.116051, 11.708944, 10.336927, 10.      , 10.698161,\n",
              "       12.447118, 15.333008, 19.253975, 23.841705], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d0Dijby7AZa",
        "outputId": "cf50130a-4439-4570-d0ff-ad4a80f71a81"
      },
      "source": [
        "tf.constant(y_pred)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              "array([[ 70.55219 ],\n",
              "       [ 75.139915],\n",
              "       [ 79.72764 ],\n",
              "       [ 84.31536 ],\n",
              "       [ 88.90308 ],\n",
              "       [ 93.49081 ],\n",
              "       [ 98.07853 ],\n",
              "       [102.66626 ],\n",
              "       [107.253975],\n",
              "       [111.841705]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5foPWc_N7GDZ",
        "outputId": "3af3febd-b536-4bb9-e7cf-f7467f9634a1"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUGocfNg7O9w",
        "outputId": "e58074c2-1cc7-4d8c-893f-eb7cd24b0318"
      },
      "source": [
        "tf.squeeze(y_pred)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([ 70.55219 ,  75.139915,  79.72764 ,  84.31536 ,  88.90308 ,\n",
              "        93.49081 ,  98.07853 , 102.66626 , 107.253975, 111.841705],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvBPpttq7Z92",
        "outputId": "234f9ebe-bf9c-4cdf-88fe-2243848e1d96"
      },
      "source": [
        "mae = tf.metrics.mean_absolute_error(y_test,tf.squeeze(y_pred))\n",
        "mae"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=3.1969466>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV2KM-Ri7kXH",
        "outputId": "7747c6aa-0704-49e5-dd4f-dfaebda76058"
      },
      "source": [
        "# Calculate the mean square error\n",
        "msc = tf.metrics.mean_squared_error(y_test,tf.squeeze(y_pred))\n",
        "msc"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=13.070175>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsDZGO2679sj"
      },
      "source": [
        "# Make some functions to reuse MAE and MSE \n",
        "\n",
        "def mae(y_true, y_pred):\n",
        "  return tf.metrics.mean_absolute_error(y_true = y_true, y_pred = tf.squeeze(y_pred))\n",
        "\n",
        "def mse(y_true = y_test, y_pred = y_pred):\n",
        "  return tf.metrics.mean_squared_error(y_true = y_true,y_pred = tf.squeeze(y_pred))\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXBdx8xI8Zpk"
      },
      "source": [
        "### Running exp to improve the model \n",
        "\n",
        "1. Get more data \n",
        "2. Make your model larger (increase the hidden layers)\n",
        "3. Train for longer\n",
        "\n",
        "Let's do 3 modelling experiments \n",
        "\n",
        "1. same as original model train for 100 epochs\n",
        "2. 2 layers train for 100 epochs\n",
        "3. 2 layres train for 500 epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXvWAWes8-yh",
        "outputId": "84bb9c43-4150-4ce9-aff4-9ea9f2888599"
      },
      "source": [
        "model_1  = tf.keras.Sequential(\n",
        "    tf.keras.layers.Dense(1)\n",
        ")\n",
        "\n",
        "model_1.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "model_1.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4411 - mae: 8.4411\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.1746 - mae: 10.1746\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.8905 - mae: 10.8905\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.8454 - mae: 8.8454\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.9702 - mae: 9.9702\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.6662 - mae: 9.6662\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.5367 - mae: 8.5367\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1883 - mae: 9.1883\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.7696 - mae: 19.7696\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7770 - mae: 9.7770\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.6754 - mae: 8.6754\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.0656 - mae: 11.0656\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.1384 - mae: 10.1384\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.3083 - mae: 12.3083\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.6564 - mae: 12.6564\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.8511 - mae: 7.8511\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.8353 - mae: 12.8353\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.7222 - mae: 10.7222\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.3489 - mae: 20.3489\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.6042 - mae: 16.6042\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.9379 - mae: 11.9379\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3387 - mae: 8.3387\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1615 - mae: 10.1615\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.7854 - mae: 10.7854\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.8666 - mae: 8.8666\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.2837 - mae: 13.2837\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3326 - mae: 10.3326\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.5982 - mae: 13.5982\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.4771 - mae: 9.4771\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.9413 - mae: 17.9413\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.7607 - mae: 23.7607\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.8531 - mae: 7.8531\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.5730 - mae: 14.5730\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.5388 - mae: 12.5388\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.6067 - mae: 8.6067\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5177 - mae: 10.5177\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1783 - mae: 10.1783\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.5831 - mae: 11.5831\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.2184 - mae: 15.2184\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.0992 - mae: 13.0992\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.2904 - mae: 9.2904\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.2725 - mae: 11.2725\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.1896 - mae: 8.1896\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.4884 - mae: 13.4884\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.0100 - mae: 14.0100\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.1858 - mae: 8.1858\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 9.0586 - mae: 9.0586\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.7517 - mae: 10.7517\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7822 - mae: 7.7822\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.4559 - mae: 9.4559\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.9478 - mae: 8.9478\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.1062 - mae: 17.1062\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.7833 - mae: 14.7833\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.8980 - mae: 21.8980\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.1789 - mae: 17.1789\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.8193 - mae: 9.8193\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3775 - mae: 9.3775\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1458 - mae: 9.1458\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4215 - mae: 10.4215\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1509 - mae: 8.1509\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.0936 - mae: 9.0936\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.1931 - mae: 7.1931\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.3593 - mae: 8.3593\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.9715 - mae: 12.9715\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.8997 - mae: 10.8997\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.0411 - mae: 16.0411\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.7130 - mae: 9.7130\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.4405 - mae: 8.4405\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.5943 - mae: 13.5943\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1832 - mae: 7.1832\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.6785 - mae: 12.6785\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.2885 - mae: 8.2885\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.8144 - mae: 6.8144\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.1282 - mae: 11.1282\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.3528 - mae: 9.3528\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0771 - mae: 11.0771\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.3896 - mae: 15.3896\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.8207 - mae: 10.8207\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.1620 - mae: 16.1620\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.0885 - mae: 12.0885\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.2394 - mae: 9.2394\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.1937 - mae: 13.1937\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6012 - mae: 10.6012\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6480 - mae: 10.6480\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1657 - mae: 9.1657\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.9378 - mae: 8.9378\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.0997 - mae: 12.0997\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.4309 - mae: 10.4309\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.9734 - mae: 6.9734\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 14.1981 - mae: 14.1981\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7101 - mae: 7.7101\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.2247 - mae: 7.2247\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.3963 - mae: 9.3963\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.4731 - mae: 8.4731\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.8779 - mae: 11.8779\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3492 - mae: 10.3492\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3588 - mae: 7.3588\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.3086 - mae: 8.3086\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7019 - mae: 9.7019\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.6947 - mae: 8.6947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8513526d50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "hlgfmDCA-j8e",
        "outputId": "15ddc402-dae1-4561-aa87-185e22ccfa7e"
      },
      "source": [
        "# Make an polt for predictions \n",
        "\n",
        "y_pred1 = model_1.predict(X_test)\n",
        "polt_predictions(predictions = y_pred1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f85134acd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3zJkDzE_iPn",
        "outputId": "5efaebe6-7d14-4647-be27-0e216e8af87e"
      },
      "source": [
        "# Calculate model_1 evaluation metrics \n",
        "mae_1 = mae(y_test, tf.squeeze(y_pred1))\n",
        "mse_1 = mse(y_test, tf.squeeze(y_pred1))\n",
        "\n",
        "mae_1,mse_1"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=8.647593>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=81.30821>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkJjFXUZAjnB",
        "outputId": "d787ad22-247a-4bab-db7b-9b21e1199aea"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Replicate model_1 and add an extra layer\n",
        "model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1) # add a second layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "model_2.fit(X_train, y_train, epochs=100, verbose=0) # set verbose to 0 for less output\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8513441050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "hNcq2lNiEeRv",
        "outputId": "7140fc75-b946-4847-a046-9775035323cb"
      },
      "source": [
        "# make and plot predictions \n",
        "\n",
        "y_pred_2 = model_2.predict(X_test)\n",
        "polt_predictions(predictions = y_pred_2)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f851336c680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtHNH2H0GvTq"
      },
      "source": [
        "# Calculate the evalution metrics \n",
        "\n",
        "mae_2 = mae(y_test,y_pred_2)\n",
        "mse_2 = mse(y_test, y_pred_2)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_2oH0dOIEy2"
      },
      "source": [
        "### Fitting the model for 500 epochs the model is over fit and the predictions are very wierd \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "O9rDuxU-Hp-u",
        "outputId": "976aa71c-e665-45e2-ad19-14cd0bfecead"
      },
      "source": [
        "# Let's compare results using the pandas DataFrame\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "model_results=[[\"model_1\", mae_1.numpy(), mse_1.numpy()],\n",
        "              [\"model_2\", mae_2.numpy(), mse_2.numpy()]]\n",
        "\n",
        "all_results = pd.DataFrame(model_results, columns=[\"model\", \"mae\", \"mse\"])\n",
        "all_results"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_1</td>\n",
              "      <td>8.647593</td>\n",
              "      <td>81.308212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model_2</td>\n",
              "      <td>1.909864</td>\n",
              "      <td>5.459540</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     model       mae        mse\n",
              "0  model_1  8.647593  81.308212\n",
              "1  model_2  1.909864   5.459540"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjFWG8V8KQHS"
      },
      "source": [
        " ### Saving our model \n",
        "\n",
        " This helps us to use he pretrained model once again\n",
        "\n",
        " There are 2 main format\n",
        "\n",
        " 1. SaveModel format \n",
        " 2. The HDF5 format "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QdyBlwHlJsk",
        "outputId": "0a6eee77-6d05-41d6-cd6c-ba565409778f"
      },
      "source": [
        "# Save model \n",
        "model.save(\"SavedModel\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: SavedModel/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfpojnw-l07b"
      },
      "source": [
        "model.save(\"SavedModel.h5\")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ1VY-7YnbHl"
      },
      "source": [
        "## Loding in a saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsOUh7Zrn5Qd"
      },
      "source": [
        "model = tf.keras.models.load_model(\"/content/SavedModel\")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBWAuv6RoJ-a",
        "outputId": "e22b1bda-40f2-47fd-9a9d-404b8d487fef"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input_layer (Dense)          (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y08pTvCqoRg8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e84a72-0226-4f45-caa9-25b2ae85f9cb"
      },
      "source": [
        "# Loding the model using the h5 format\n",
        "loaded_model = tf.keras.models.load_model(\"/content/SavedModel.h5\")\n",
        "loaded_model.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input_layer (Dense)          (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye4ouRLXop97"
      },
      "source": [
        "### A larger model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acac-YkyrA7O"
      },
      "source": [
        "# Import \n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "tcMoGHXCryrg",
        "outputId": "2d9db722-fd93-41b1-d5f2-10a02d61d65d"
      },
      "source": [
        "#Reading the dataset \n",
        "\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "SJzCMB1jr9Pm",
        "outputId": "da6ffaf8-7458-461b-9ddd-ffb6ac3ad9a0"
      },
      "source": [
        "# One hot encode\n",
        "insurance_onehot = pd.get_dummies(insurance)\n",
        "insurance_onehot.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "Euut0FfFujTt",
        "outputId": "bf7f1a93-2fdc-441e-c213-cc46be4100a4"
      },
      "source": [
        "# Create X and y values\n",
        "X = insurance_onehot.drop('charges',axis=1)\n",
        "y = insurance_onehot[\"charges\"]\n",
        "X.head()\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx6WgL1ovf80",
        "outputId": "1f1aa80a-e1af-4fb5-e128-97555d80b7b1"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    16884.92400\n",
              "1     1725.55230\n",
              "2     4449.46200\n",
              "3    21984.47061\n",
              "4     3866.85520\n",
              "Name: charges, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZcQoGojyN1f",
        "outputId": "2a37c056-17f9-4da9-91f6-f458136e2ca8"
      },
      "source": [
        "# Creating the training and test set \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "len(X), len(X_train)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1338, 1070)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tiqe8kkCzI6z",
        "outputId": "4fc8909e-cf31-459d-f816-da8a171582da"
      },
      "source": [
        "# Build a neural network \n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "insurance_model = tf.keras.Sequential([\n",
        "                                       tf.keras.layers.Dense(10),\n",
        "                                       tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Complie the model\n",
        "\n",
        "insurance_model.compile(loss = tf.keras.losses.mae,\n",
        "                        optimizer = tf.keras.optimizers.SGD(),\n",
        "                        metrics=[\"mae\"])\n",
        "\n",
        "# fit the model \n",
        "\n",
        "insurance_model.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10200.7270 - mae: 10200.7270\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7718.1916 - mae: 7718.1916\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6983.7825 - mae: 6983.7825\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8083.4823 - mae: 8083.4823\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7793.8446 - mae: 7793.8446\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7618.4114 - mae: 7618.4114\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7678.4982 - mae: 7678.4982\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7780.4294 - mae: 7780.4294\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7588.8130 - mae: 7588.8130\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7520.6832 - mae: 7520.6832\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8309.7820 - mae: 8309.7820\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7748.0187 - mae: 7748.0187\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7888.3563 - mae: 7888.3563\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7731.1162 - mae: 7731.1162\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7786.1045 - mae: 7786.1045\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8343.8852 - mae: 8343.8852\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7142.3603 - mae: 7142.3603\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8070.0509 - mae: 8070.0509\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7604.8295 - mae: 7604.8295\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7945.1267 - mae: 7945.1267\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6864.6823 - mae: 6864.6823\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7505.7909 - mae: 7505.7909\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7621.7381 - mae: 7621.7381\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7262.7541 - mae: 7262.7541\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8156.1948 - mae: 8156.1948\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7246.2706 - mae: 7246.2706\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7562.7815 - mae: 7562.7815\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7842.6213 - mae: 7842.6213\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7153.8770 - mae: 7153.8770\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7723.4947 - mae: 7723.4947\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8310.0627 - mae: 8310.0627\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7734.9657 - mae: 7734.9657\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7403.4652 - mae: 7403.4652\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7482.6282 - mae: 7482.6282\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7198.8918 - mae: 7198.8918\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7484.1018 - mae: 7484.1018\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7701.6289 - mae: 7701.6289\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6923.6146 - mae: 6923.6146\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7673.7907 - mae: 7673.7907\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7670.9196 - mae: 7670.9196\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7774.5884 - mae: 7774.5884\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7413.0884 - mae: 7413.0884\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7793.8663 - mae: 7793.8663\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7239.3576 - mae: 7239.3576\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7402.6552 - mae: 7402.6552\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7167.7285 - mae: 7167.7285\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7716.9019 - mae: 7716.9019\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7509.9126 - mae: 7509.9126\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7216.6764 - mae: 7216.6764\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7354.2578 - mae: 7354.2578\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7587.3342 - mae: 7587.3342\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7697.7629 - mae: 7697.7629\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7084.7632 - mae: 7084.7632\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7366.1158 - mae: 7366.1158\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7354.5014 - mae: 7354.5014\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7201.4709 - mae: 7201.4709\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7612.1704 - mae: 7612.1704\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7684.3347 - mae: 7684.3347\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7315.3648 - mae: 7315.3648\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7381.6651 - mae: 7381.6651\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7842.5243 - mae: 7842.5243\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7346.2639 - mae: 7346.2639\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7634.5370 - mae: 7634.5370\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6976.2132 - mae: 6976.2132\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7608.7969 - mae: 7608.7969\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7275.7894 - mae: 7275.7894\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7244.1641 - mae: 7244.1641\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7553.0951 - mae: 7553.0951\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8028.1959 - mae: 8028.1959\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7150.7139 - mae: 7150.7139\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7137.5192 - mae: 7137.5192\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6708.9291 - mae: 6708.9291\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7554.2730 - mae: 7554.2730\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7060.4078 - mae: 7060.4078\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7564.8157 - mae: 7564.8157\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7016.7827 - mae: 7016.7827\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7936.9763 - mae: 7936.9763\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6828.1386 - mae: 6828.1386\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6875.0794 - mae: 6875.0794\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6770.6313 - mae: 6770.6313\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7216.2090 - mae: 7216.2090\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7774.2738 - mae: 7774.2738\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7156.2552 - mae: 7156.2552\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7436.0038 - mae: 7436.0038\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6855.7935 - mae: 6855.7935\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7768.8273 - mae: 7768.8273\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7014.5799 - mae: 7014.5799\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7525.7778 - mae: 7525.7778\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6994.6074 - mae: 6994.6074\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7677.9609 - mae: 7677.9609\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7210.0507 - mae: 7210.0507\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7335.2230 - mae: 7335.2230\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7235.0912 - mae: 7235.0912\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6728.8876 - mae: 6728.8876\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7811.5179 - mae: 7811.5179\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7430.2755 - mae: 7430.2755\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6876.5976 - mae: 6876.5976\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7070.8705 - mae: 7070.8705\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7118.6875 - mae: 7118.6875\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6880.6744 - mae: 6880.6744\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8513dceb10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZcapGfKz2Eo",
        "outputId": "73ef4a18-5e78-4f9d-d7c3-bcfa77804230"
      },
      "source": [
        "insurance_model.evaluate(X_test,y_test)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 7023.3291 - mae: 7023.3291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7023.3291015625, 7023.3291015625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITcjtUpS1Hl-"
      },
      "source": [
        "### Let's improve the model\n",
        "\n",
        "To try improve our model try this\n",
        "\n",
        "1. Add extra layer to imporve the model \n",
        "2. Train for longer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STZIfqaT1j2z",
        "outputId": "3cb6b63d-c263-4b0e-835c-568f77f5d0fb"
      },
      "source": [
        "# Build a neural network \n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "insurance_model = tf.keras.Sequential([\n",
        "                                       tf.keras.layers.Dense(100,activation=\"relu\"),\n",
        "                                       tf.keras.layers.Dense(10),\n",
        "                                       tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Complie the model\n",
        "\n",
        "insurance_model.compile(loss = tf.keras.losses.mae,\n",
        "                        optimizer = tf.keras.optimizers.Adam(),\n",
        "                        metrics=[\"mae\"])\n",
        "\n",
        "# fit the model \n",
        "\n",
        "insurance_model.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13279.1998 - mae: 13279.1998\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12866.8038 - mae: 12866.8038\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12483.1525 - mae: 12483.1525\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12856.0916 - mae: 12856.0916\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12190.9897 - mae: 12190.9897\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11128.5881 - mae: 11128.5881\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9938.5032 - mae: 9938.5032\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8981.9454 - mae: 8981.9454\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7950.4780 - mae: 7950.4780\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7725.8453 - mae: 7725.8453\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7848.2072 - mae: 7848.2072\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7408.1751 - mae: 7408.1751\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7692.5076 - mae: 7692.5076\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7449.0508 - mae: 7449.0508\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7681.2243 - mae: 7681.2243\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7618.0144 - mae: 7618.0144\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7001.5746 - mae: 7001.5746\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7190.7034 - mae: 7190.7034\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7225.1564 - mae: 7225.1564\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7118.1494 - mae: 7118.1494\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6534.5118 - mae: 6534.5118\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6741.9013 - mae: 6741.9013\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7177.7764 - mae: 7177.7764\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6907.9477 - mae: 6907.9477\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7558.4573 - mae: 7558.4573\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6786.3012 - mae: 6786.3013\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7179.9291 - mae: 7179.9291\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7427.8419 - mae: 7427.8419\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6750.0536 - mae: 6750.0536\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7194.2948 - mae: 7194.2948\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7429.4295 - mae: 7429.4295\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6899.8949 - mae: 6899.8949\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7077.4994 - mae: 7077.4994\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6914.4883 - mae: 6914.4883\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6978.7522 - mae: 6978.7522\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6859.6350 - mae: 6859.6350\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7003.5368 - mae: 7003.5368\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6508.8642 - mae: 6508.8642\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6899.9939 - mae: 6899.9939\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6796.7903 - mae: 6796.7903\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6725.1201 - mae: 6725.1201\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6600.7758 - mae: 6600.7758\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6612.8590 - mae: 6612.8590\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6373.6575 - mae: 6373.6575\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6407.7335 - mae: 6407.7335\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6160.7520 - mae: 6160.7520\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6730.2131 - mae: 6730.2131\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6487.8027 - mae: 6487.8027\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6215.4232 - mae: 6215.4232\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6492.4984 - mae: 6492.4984\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6398.1447 - mae: 6398.1447\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6398.6349 - mae: 6398.6349\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6052.7345 - mae: 6052.7345\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6496.6948 - mae: 6496.6948\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6285.8685 - mae: 6285.8685\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6355.4589 - mae: 6355.4589\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6648.8888 - mae: 6648.8888\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6436.6264 - mae: 6436.6264\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5981.7935 - mae: 5981.7935\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6312.7416 - mae: 6312.7416\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6836.0039 - mae: 6836.0039\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6425.6551 - mae: 6425.6551\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6458.1568 - mae: 6458.1568\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5964.1923 - mae: 5964.1923\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6352.9957 - mae: 6352.9957\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6102.5077 - mae: 6102.5077\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6206.6240 - mae: 6206.6240\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6140.5782 - mae: 6140.5782\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6640.6853 - mae: 6640.6853\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5820.8964 - mae: 5820.8964\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6229.5662 - mae: 6229.5662\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5899.1645 - mae: 5899.1645\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6435.2382 - mae: 6435.2382\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6251.2737 - mae: 6251.2737\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6602.6848 - mae: 6602.6848\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5826.7880 - mae: 5826.7880\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6575.1238 - mae: 6575.1238\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5639.3341 - mae: 5639.3341\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5261.0946 - mae: 5261.0946\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5379.1296 - mae: 5379.1296\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6009.2430 - mae: 6009.2430\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6772.0659 - mae: 6772.0659\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5915.1611 - mae: 5915.1611\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5782.6578 - mae: 5782.6578\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5335.1734 - mae: 5335.1734\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6142.7670 - mae: 6142.7670\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5703.1801 - mae: 5703.1801\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6047.9379 - mae: 6047.9379\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5688.5713 - mae: 5688.5713\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6281.7943 - mae: 6281.7943\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5914.8480 - mae: 5914.8480\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6005.6630 - mae: 6005.6630\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5558.6796 - mae: 5558.6796\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5376.6802 - mae: 5376.6802\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5836.3805 - mae: 5836.3805\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5954.8944 - mae: 5954.8944\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5322.1033 - mae: 5322.1033\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5392.0586 - mae: 5392.0586\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5117.8939 - mae: 5117.8939\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5256.1713 - mae: 5256.1713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8513cbaad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQALSaDm1sNH",
        "outputId": "af6838db-3b82-48b7-9fdb-c4a93ea38f4e"
      },
      "source": [
        "insurance_model.evaluate(X_test,y_test)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 5434.2031 - mae: 5434.2031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5434.203125, 5434.203125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me9Z2nbX2dHH",
        "outputId": "28f8ead4-7dd7-43d1-da85-d24a3fa08785"
      },
      "source": [
        "# Build a neural network \n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "insurance_model3 = tf.keras.Sequential([\n",
        "                                       tf.keras.layers.Dense(100),\n",
        "                                       tf.keras.layers.Dense(10),\n",
        "                                       tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Complie the model\n",
        "\n",
        "insurance_model.compile(loss = tf.keras.losses.mae,\n",
        "                        optimizer = tf.keras.optimizers.Adam(),\n",
        "                        metrics=[\"mae\"])\n",
        "\n",
        "# fit the model \n",
        "\n",
        "insurance_model.fit(X_train,y_train,epochs=200)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5442.2364 - mae: 5442.2364\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5269.1558 - mae: 5269.1558\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5104.0952 - mae: 5104.0952\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5650.6700 - mae: 5650.6700\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5444.9491 - mae: 5444.9491\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5444.5333 - mae: 5444.5333\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5330.1636 - mae: 5330.1636\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5543.9332 - mae: 5543.9332\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5416.2573 - mae: 5416.2573\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5416.5939 - mae: 5416.5939\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5614.0886 - mae: 5614.0886\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5210.7528 - mae: 5210.7528\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5372.9619 - mae: 5372.9619\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5132.3650 - mae: 5132.3650\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5415.6677 - mae: 5415.6677\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5223.8888 - mae: 5223.8888\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4606.7864 - mae: 4606.7864\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4751.8634 - mae: 4751.8634\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4663.8570 - mae: 4663.8570\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4655.2846 - mae: 4655.2846\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4149.7161 - mae: 4149.7161\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4241.7375 - mae: 4241.7375\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4599.8243 - mae: 4599.8243\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4344.7293 - mae: 4344.7293\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4786.4317 - mae: 4786.4317\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4145.3023 - mae: 4145.3023\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4433.9469 - mae: 4433.9469\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4526.7783 - mae: 4526.7783\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3864.2455 - mae: 3864.2455\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4202.4008 - mae: 4202.4008\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4447.8803 - mae: 4447.8803\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3912.4090 - mae: 3912.4090\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4051.8171 - mae: 4051.8171\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3834.7683 - mae: 3834.7683\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3915.4178 - mae: 3915.4178\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3713.8654 - mae: 3713.8654\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3840.2690 - mae: 3840.2690\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3485.7450 - mae: 3485.7450\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3830.1744 - mae: 3830.1744\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3653.0661 - mae: 3653.0661\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3719.2410 - mae: 3719.2410\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3757.5222 - mae: 3757.5222\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3704.6797 - mae: 3704.6797\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3535.6869 - mae: 3535.6869\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3470.1758 - mae: 3470.1758\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3458.9248 - mae: 3458.9248\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3871.2935 - mae: 3871.2935\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3549.5900 - mae: 3549.5900\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.4843 - mae: 3478.4843\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3592.0171 - mae: 3592.0171\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3594.3129 - mae: 3594.3129\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3590.0842 - mae: 3590.0842\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3383.2377 - mae: 3383.2377\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3613.7127 - mae: 3613.7127\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3468.6290 - mae: 3468.6290\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3507.3795 - mae: 3507.3795\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3810.2874 - mae: 3810.2874\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3532.8317 - mae: 3532.8317\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3383.6384 - mae: 3383.6384\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3628.7627 - mae: 3628.7627\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3733.5822 - mae: 3733.5822\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3749.0395 - mae: 3749.0395\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3687.2655 - mae: 3687.2655\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3516.6712 - mae: 3516.6712\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3564.3423 - mae: 3564.3423\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3363.6750 - mae: 3363.6750\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3518.3657 - mae: 3518.3657\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.1894 - mae: 3536.1894\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3668.5570 - mae: 3668.5570\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3289.5166 - mae: 3289.5166\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3496.1874 - mae: 3496.1874\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3312.8254 - mae: 3312.8254\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3650.9054 - mae: 3650.9054\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3530.8815 - mae: 3530.8815\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3795.7360 - mae: 3795.7360\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3364.2582 - mae: 3364.2582\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3650.2578 - mae: 3650.2578\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3370.7198 - mae: 3370.7198\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3067.9245 - mae: 3067.9245\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3137.9840 - mae: 3137.9840\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3388.8324 - mae: 3388.8324\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3904.1288 - mae: 3904.1288\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3465.1702 - mae: 3465.1702\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3315.0653 - mae: 3315.0653\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2992.9470 - mae: 2992.9470\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3517.0171 - mae: 3517.0171\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3393.9972 - mae: 3393.9972\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3531.7017 - mae: 3531.7017\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3240.8062 - mae: 3240.8062\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3611.0569 - mae: 3611.0569\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3481.8184 - mae: 3481.8184\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3543.1352 - mae: 3543.1352\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3335.0042 - mae: 3335.0042\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3195.0623 - mae: 3195.0623\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3353.4700 - mae: 3353.4700\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3523.8471 - mae: 3523.8471\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3259.6234 - mae: 3259.6234\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3245.0493 - mae: 3245.0493\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3013.9823 - mae: 3013.9823\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3201.5601 - mae: 3201.5601\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3322.3893 - mae: 3322.3893\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3278.8629 - mae: 3278.8629\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3031.1180 - mae: 3031.1180\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3494.2274 - mae: 3494.2274\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3199.7851 - mae: 3199.7851\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3400.4951 - mae: 3400.4951\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3561.7925 - mae: 3561.7925\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3369.5216 - mae: 3369.5216\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3613.0494 - mae: 3613.0494\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3715.9961 - mae: 3715.9961\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3575.9551 - mae: 3575.9551\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3280.4553 - mae: 3280.4553\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3311.2606 - mae: 3311.2606\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3480.4545 - mae: 3480.4545\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3347.1996 - mae: 3347.1996\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3584.3959 - mae: 3584.3959\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3286.4089 - mae: 3286.4089\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3322.9012 - mae: 3322.9012\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3424.3961 - mae: 3424.3961\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3569.5385 - mae: 3569.5385\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3565.0829 - mae: 3565.0829\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3320.0445 - mae: 3320.0445\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3220.6503 - mae: 3220.6503\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3195.8373 - mae: 3195.8373\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3459.8408 - mae: 3459.8408\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3324.3970 - mae: 3324.3970\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3383.3009 - mae: 3383.3009\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3286.5443 - mae: 3286.5443\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3462.9955 - mae: 3462.9955\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3315.3877 - mae: 3315.3877\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3187.1001 - mae: 3187.1001\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3537.9269 - mae: 3537.9269\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3448.5076 - mae: 3448.5076\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3438.0215 - mae: 3438.0215\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3273.6938 - mae: 3273.6938\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3261.1814 - mae: 3261.1814\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3174.2776 - mae: 3174.2776\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3495.1471 - mae: 3495.1471\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3153.0520 - mae: 3153.0520\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3298.1875 - mae: 3298.1875\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3535.5901 - mae: 3535.5901\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3172.8532 - mae: 3172.8532\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3215.9641 - mae: 3215.9641\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3357.2737 - mae: 3357.2737\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3506.6243 - mae: 3506.6243\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3305.2947 - mae: 3305.2947\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3323.6677 - mae: 3323.6677\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3178.2061 - mae: 3178.2061\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3057.1871 - mae: 3057.1871\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3356.9201 - mae: 3356.9201\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3268.9855 - mae: 3268.9855\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3176.6680 - mae: 3176.6680\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3127.8446 - mae: 3127.8446\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3353.2375 - mae: 3353.2375\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3082.4027 - mae: 3082.4027\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3056.1549 - mae: 3056.1549\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2986.4998 - mae: 2986.4998\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3259.8945 - mae: 3259.8945\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3129.7238 - mae: 3129.7238\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3202.9526 - mae: 3202.9526\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3102.8881 - mae: 3102.8881\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3186.4331 - mae: 3186.4331\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2986.1428 - mae: 2986.1428\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3127.4662 - mae: 3127.4662\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3032.4898 - mae: 3032.4898\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3245.1620 - mae: 3245.1620\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3314.1136 - mae: 3314.1136\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3261.9330 - mae: 3261.9330\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3019.5228 - mae: 3019.5228\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3332.2732 - mae: 3332.2732\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3141.0915 - mae: 3141.0915\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3211.5178 - mae: 3211.5178\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3249.6153 - mae: 3249.6153\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3022.3261 - mae: 3022.3261\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3263.5787 - mae: 3263.5787\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3178.5995 - mae: 3178.5995\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3087.1198 - mae: 3087.1198\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3263.3491 - mae: 3263.3491\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2889.2855 - mae: 2889.2855\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3279.9776 - mae: 3279.9776\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3278.5395 - mae: 3278.5395\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3087.9993 - mae: 3087.9993\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2880.4160 - mae: 2880.4160\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2890.0421 - mae: 2890.0421\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2848.5696 - mae: 2848.5696\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3144.4423 - mae: 3144.4423\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3162.8037 - mae: 3162.8037\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3007.4577 - mae: 3007.4577\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2807.1185 - mae: 2807.1185\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3077.1912 - mae: 3077.1912\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2901.2777 - mae: 2901.2777\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2879.0088 - mae: 2879.0088\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2910.5670 - mae: 2910.5670\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3122.9222 - mae: 3122.9222\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2846.1905 - mae: 2846.1905\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2861.1030 - mae: 2861.1030\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3138.5557 - mae: 3138.5557\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2755.2073 - mae: 2755.2073\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3023.5566 - mae: 3023.5566\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3145.8308 - mae: 3145.8308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8513b03610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhyA101C3K06"
      },
      "source": [
        "# insurance_model3.evaluatte(X_test,y_test)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "B8zJyvhK6F_3",
        "outputId": "97168c73-09f3-42c7-d53a-71b20ba9605e"
      },
      "source": [
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOMOpKIA3afF"
      },
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "# Create a column transformer \n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), ['age', 'bmi', 'children']), # turn those to onehot vector\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"), ['sex', 'smoker','region'])\n",
        ")\n",
        "\n",
        "# Create X & y\n",
        "X = insurance.drop('charges', axis=1)\n",
        "y = insurance['charges']\n",
        "\n",
        "# Build our train test sets \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit col transformer to training to training data\n",
        "\n",
        "ct.fit(X_train)\n",
        "\n",
        "# Transform training data with normalisation(MinMaxScaler) and OneHotEncoder\n",
        "X_train_normal = ct.transform(X_train)\n",
        "X_test_normal = ct.transform(X_test)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbvnWUKy7oQw",
        "outputId": "b719d02a-e438-4295-aa06-487bc4bb355e"
      },
      "source": [
        "# What does our data look like \n",
        "\n",
        "X_train_normal[0]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
              "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMh0Bn5F7xpl",
        "outputId": "8e389d1c-bdf6-4a23-c59d-b77635c9810b"
      },
      "source": [
        "X_train.shape, X_train_normal.shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 6), (1070, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd-QslFg8MkS"
      },
      "source": [
        "Data has been normalized and one hot encoded. Let's build the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quqUa4wR8KTE",
        "outputId": "18afda6e-beee-463c-ef28-054f7323156a"
      },
      "source": [
        "#Set the seed \n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model \n",
        "\n",
        "normal_insurance_model = tf.keras.Sequential([\n",
        "                                              tf.keras.layers.Dense(100),\n",
        "                                              tf.keras.layers.Dense(10),\n",
        "                                              tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model \n",
        "\n",
        "normal_insurance_model.compile(loss = tf.keras.losses.mae,\n",
        "                        optimizer = tf.keras.optimizers.Adam(),\n",
        "                        metrics=[\"mae\"])\n",
        "\n",
        "# Fitting the model \n",
        "\n",
        "normal_insurance_model.fit(X_train_normal,y_train, epochs=100)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13296.4687 - mae: 13296.4687\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12948.4238 - mae: 12948.4238\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12705.2199 - mae: 12705.2199\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13369.7395 - mae: 13369.7395\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13230.8565 - mae: 13230.8565\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12995.1988 - mae: 12995.1988\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12876.1058 - mae: 12876.1058\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13004.0395 - mae: 13004.0395\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12508.0465 - mae: 12508.0465\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12304.9941 - mae: 12304.9941\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12190.6077 - mae: 12190.6077\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10948.1231 - mae: 10948.1231\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11033.2697 - mae: 11033.2697\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10209.3786 - mae: 10209.3786\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9943.5374 - mae: 9943.5374\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9393.3770 - mae: 9393.3770\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8554.0262 - mae: 8554.0262\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8463.0881 - mae: 8463.0881\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8238.9919 - mae: 8238.9919\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7992.1421 - mae: 7992.1421\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7246.4886 - mae: 7246.4886\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7520.6745 - mae: 7520.6745\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7862.2001 - mae: 7862.2001\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7617.0075 - mae: 7617.0075\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8118.1866 - mae: 8118.1866\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7381.5776 - mae: 7381.5776\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7759.2989 - mae: 7759.2989\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7961.3149 - mae: 7961.3149\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7357.1595 - mae: 7357.1595\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7670.5824 - mae: 7670.5824\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7833.2163 - mae: 7833.2163\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7408.4354 - mae: 7408.4354\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7603.6624 - mae: 7603.6624\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7385.2735 - mae: 7385.2735\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7340.4552 - mae: 7340.4552\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7276.7012 - mae: 7276.7012\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7342.1813 - mae: 7342.1813\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6918.2723 - mae: 6918.2723\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7252.1239 - mae: 7252.1239\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7029.9503 - mae: 7029.9503\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6984.8116 - mae: 6984.8116\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6884.6927 - mae: 6884.6927\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6755.5834 - mae: 6755.5834\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6608.4542 - mae: 6608.4542\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6537.6250 - mae: 6537.6250\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6454.2749 - mae: 6454.2749\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6729.0266 - mae: 6729.0266\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6517.0467 - mae: 6517.0467\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6209.9382 - mae: 6209.9382\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6433.2530 - mae: 6433.2530\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6253.4749 - mae: 6253.4749\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6122.7599 - mae: 6122.7599\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5797.8437 - mae: 5797.8437\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6036.6884 - mae: 6036.6884\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5688.6438 - mae: 5688.6438\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5664.2596 - mae: 5664.2596\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5857.4065 - mae: 5857.4065\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5509.3851 - mae: 5509.3851\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5316.6021 - mae: 5316.6021\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5322.8682 - mae: 5322.8682\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5458.1975 - mae: 5458.1975\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5230.6238 - mae: 5230.6238\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5084.5996 - mae: 5084.5996\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4677.8220 - mae: 4677.8220\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4707.1114 - mae: 4707.1114\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4361.7464 - mae: 4361.7464\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4333.7886 - mae: 4333.7886\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4294.6894 - mae: 4294.6894\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4365.7156 - mae: 4365.7156\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3931.4925 - mae: 3931.4925\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4040.8882 - mae: 4040.8882\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3725.7784 - mae: 3725.7784\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4041.0184 - mae: 4041.0184\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3849.4080 - mae: 3849.4080\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4063.8185 - mae: 4063.8185\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3594.6088 - mae: 3594.6088\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3877.1158 - mae: 3877.1158\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3571.6360 - mae: 3571.6360\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3272.2000 - mae: 3272.2000\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3333.3792 - mae: 3333.3792\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3560.1420 - mae: 3560.1420\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4082.1636 - mae: 4082.1636\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3690.6052 - mae: 3690.6052\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3491.1416 - mae: 3491.1416\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3196.7645 - mae: 3196.7645\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3696.4113 - mae: 3696.4113\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3584.8877 - mae: 3584.8877\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3717.8066 - mae: 3717.8066\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3437.4367 - mae: 3437.4367\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3799.4694 - mae: 3799.4694\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3660.1358 - mae: 3660.1358\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3743.4220 - mae: 3743.4220\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.3570 - mae: 3536.3570\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3439.5848 - mae: 3439.5848\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3570.7315 - mae: 3570.7315\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3734.5114 - mae: 3734.5114\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3444.5724 - mae: 3444.5724\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3465.0853 - mae: 3465.0853\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3225.0305 - mae: 3225.0305\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3421.0634 - mae: 3421.0634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8513cb28d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQhV42kZ9qEt",
        "outputId": "2d7683e2-ce6f-4051-a08f-c0de321a5740"
      },
      "source": [
        "normal_insurance_model.evaluate(X_test_normal, y_test)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3438.7844 - mae: 3438.7844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3438.784423828125, 3438.784423828125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53toMFJF-TUm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}